{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_2_ensemble_learning_boosting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM7Dfd58ZgA7H//+mRY671z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Richish/hands_on_ml/blob/master/7_2_ensemble_learning_boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnnXjMk4usYQ",
        "colab_type": "text"
      },
      "source": [
        "# Boosting\n",
        "Boosting (originally called hypothesis boosting) refers to any Ensemble method that can combine several weak learners into a strong learner. The general idea of most boosting methods is to **train predictors sequentially**, each trying to correct its predecessor.\n",
        "\n",
        "2 of the most popular boosting methods:\n",
        "1. Ada Boost.(Adaptive Boosting)\n",
        "2. Gradient Boosting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmrNTsZ4usnq",
        "colab_type": "text"
      },
      "source": [
        "# Ada Boost\n",
        "\n",
        "## Technique used by Ada‐Boost:\n",
        "A new predictor corrects its predecessor by paying a bit more attention to the training instances that the predecessor underfitted. This results in new predictors focusing more and more on the hard cases. \n",
        "\n",
        "## Example:\n",
        "To build an AdaBoost classifier, a first base classifier (such as a DecisionTree or any other classifier) is trained and used to make predictions on the training set. The relative weight of misclassified training instances is then increased. A second classifier is trained using the updated weights and again it makes predictions on the training set, weights are updated, and so on.\n",
        "\n",
        "Once all predictors are trained, the ensemble makes predictions very much like bagging\n",
        "or pasting, except that predictors have different weights depending on their\n",
        "overall accuracy on the weighted training set.\n",
        "\n",
        "## Comparison with gradient descent:\n",
        "This sequential learning technique has some similarities with Gradient Descent, except that instead of tweaking a single predictor’s parameters to minimize a cost function, AdaBoost adds predictors to the ensemble, gradually making it better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Ejit1Qusq3",
        "colab_type": "text"
      },
      "source": [
        "## Drawback of this sequential technique\n",
        "It cannot be parallelized (or only partially), since each predictor\n",
        "can only be trained after the previous predictor has been\n",
        "trained and evaluated. As a result, it does not scale as well as bagging\n",
        "or pasting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwsRwvVVusuM",
        "colab_type": "text"
      },
      "source": [
        "## Ada Boost algorithm details\n",
        "\n",
        "i -> ith instance.\n",
        "j -> jth predictor.\n",
        "{} -> subscript\n",
        "\n",
        "w^(i) - > Weight of ith instance(initialised to 1/m for each instance).\n",
        "These w^(i) ar what needs to be updated in each predictor.\n",
        "\n",
        "r{j} denoted as r{j} is the weighted error rate of all the instances on jth predictor.\n",
        "\n",
        "r{j} = (from i=1 to m if ÿ{j}^(i) != y^(i)) Σw^(i)) / ((from i=1 to m)Σw^(i))\n",
        "\n",
        "Predictor weight, à{j} = ń log((1-r{j})/r{j})\n",
        "here, ń = learning rate parameter(default = 1).\n",
        "\n",
        "Next, the instance weights are updated:\n",
        "w^(i) = w^(i) if ÿ{j}^(i) = y^(i)\n",
        "w^(i) = w^(i)*exp(à{j})) if ÿ{j}^(i) != y^(i)\n",
        "\n",
        "Then all the instance weights are normalized (i.e., divided by (from i = 1to m)Σw^(i)).\n",
        "\n",
        "Finally, a new predictor is trained using the updated weights, and the whole process is repeated (the new predictor’s weight is computed, the instance weights are updated,then another predictor is trained, and so on). The algorithm stops when the desired number of predictors is reached, or when a perfect predictor is found.\n",
        "\n",
        "To make predictions, AdaBoost simply computes the predictions of all the predictors and weighs them using the predictor weights α{j}. The predicted class is the one that receives the majority of weighted votes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcayqRDKusxf",
        "colab_type": "text"
      },
      "source": [
        "## SAMME16 (Stagewise Additive Modeling using a Multiclass Exponential loss function)\n",
        "\n",
        "Scikit-Learn actually uses a multiclass version of AdaBoost called SAMME16 (which stands for Stagewise Additive Modeling using a Multiclass Exponential loss function). When there are just two classes, SAMME is equivalent to AdaBoost. Moreover, if the predictors can estimate class probabilities (i.e., if they have a predict_proba() method), Scikit-Learn can use a variant of SAMME called SAMME.R (the R stands for “Real”), which relies on class probabilities rather than predictions and generally performs better.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jPMevzSZRk8",
        "colab_type": "text"
      },
      "source": [
        "## Example in sklearn:\n",
        "The following code trains an AdaBoost classifier based on 200 Decision Stumps using Scikit-Learn’s AdaBoostClassifier class (as you might expect, there is also an Ada BoostRegressor class). A Decision Stump is a Decision Tree with max_depth=1—in other words, a tree composed of a single decision node plus two leaf nodes. This is the default base estimator for the AdaBoostClassifier class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0wZQwLsZajU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65ff0a3c-c6d9-4878-be57-c91a28c3a096"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X, y = make_moons(n_samples=10_000, noise=0.4, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
        "    learning_rate=0.5, algorithm=\"SAMME.R\", random_state=42\n",
        ")\n",
        "ada_clf.fit(X_train, y_train)\n",
        "y_pred = ada_clf.predict(X_test)\n",
        "accuracy_score(y_true=y_test, y_pred=y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T_ZdIZAbGYO",
        "colab_type": "text"
      },
      "source": [
        "## Hyperpamater tuning\n",
        "If your AdaBoost ensemble is overfitting the training set, you can\n",
        "try reducing the number of estimators or more strongly regularizing\n",
        "the base estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXCeAOeEbK3f",
        "colab_type": "text"
      },
      "source": [
        "# Gradient boosting(Gradient Tree Boosting, or Gradient Boosted Regression Trees (GBRT))\n",
        "\n",
        "Just like AdaBoost, Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor.\n",
        "\n",
        "But, Instead of tweaking the instance weights at every iteration like AdaBoost does, this method tries to fit the new predictor to the residual errors made by the previous predictor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRqhS72-bLVI",
        "colab_type": "text"
      },
      "source": [
        "## Basic implementation of GBRT using decision trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC45hr1tcGAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data prep for quadratic dataset for regression\n",
        "import numpy as np\n",
        "m=100\n",
        "X=6*np.random.rand(m,1)-3\n",
        "y=0.5*(X**2) + (X) + (2 + np.random.randn(m, 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HS5PX7deBUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8d561477-e049-447d-a6f2-ddd5b4ee4101"
      },
      "source": [
        "# First, let’s fit a DecisionTreeRegressor to the training set:\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg1.fit(X, y)\n",
        "\n",
        "# Now train a second DecisionTreeRegressor on the residual errors made by the first predictor:\n",
        "y2 = y - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg2.fit(X, y2)\n",
        "\n",
        "# Then we train a third regressor on the residual errors made by the second predictor:\n",
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg3.fit(X, y3)\n",
        "\n",
        "# Now we have an ensemble containing three trees. It can make predictions on a new\n",
        "# instance simply by adding up the predictions of all the trees:\n",
        "y_pred = sum(tree.predict(X) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
        "\n",
        "# plot values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, y, 'bo')\n",
        "plt.plot(X, y_pred, 'ro')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAY2klEQVR4nO3dfYhs913H8c93995rs2lqm81S0jzMJhCKoZQ+XIoaKaUPGktpKig0bkp8gEtSaqNQNHjBoHJRUYoXEfFiUmPv2CJJpaVEba3FWrCxmzbaPPQhxNyb1LbZJtTkuoUkd7/+MTPZubPnzJyH3znn9zv7fsGP3T1z5pzfmZ35nt/8Hs3dBQBIz1LXGQAAVEMAB4BEEcABIFEEcABIFAEcABJ1oM2TXXTRRb6+vt7mKQEgeffdd9/33X1tdnurAXx9fV2bm5ttnhIAkmdmp7K2U4UCAIkigANAogjgAJAoAjgAJIoADgCJIoADQAOGQ2l9XVpaGv0cDsOfo9VuhACwHwyH0pEj0vb26O9Tp0Z/S9LGRrjzUAIHgMCOHt0N3hPb26PtIRHAASCw06fLba+KAA4AgV1+ebntVRHAASCwY8eklZVzt62sjLaHRAAHgMA2NqQTJ6TBQDIb/TxxImwDpkQvFABoxMZG+IA9ixI4ACSKAA4AiVoYwM3sDjN70swemNp2oZl91sy+Nf75imazCQCJMctOARUpgf+1pGtntt0q6XPufpWkz43/BgBI8wN1wCC+MIC7+xckPT2z+TpJd45/v1PSe4LlCABQSNU68Fe6+3fGv39X0ivzdjSzI2a2aWabW1tbFU8HAJhVuxHT3V2Sz3n8hLsfdvfDa2t71uQEAFRUNYB/z8wulqTxzyfDZQkA0pdVqnVJOwHPUTWAf0rSjePfb5T0yTDZAYBuBZnH212TqonZdOUgt8KitCLdCD8m6d8lvdrMnjCzX5X0h5LeYWbfkvT28d8AkLTJPN6nTknuu/N4lw3iw6G0LNfSTFqWB52R0EZV2O04fPiwb25utnY+AChjfX0UtGcNBtJjj9U/TpVjSZKZ3efuh2e3MxITAMZCzeM9b/+QMxISwAFgLNQ83nn7r66ypBoANCLUPN55xzl+vF7+ZhHAAWAs1Dzebc0HTiMmAESORkwA6BkCOAAkigAOAIkigANASUGG2wfAosYAUMJkuP329ujvyXB7qflFjGdRAgeAaQuWQbv+BtOZbdOOdtOZbdP1N4RdLq0ISuAAMJG33JnZaHYrM5mk3FA92a8llMABoIS84N1++ZsADgDJIoADwFhe5YcveLwrBHAAGMta4Hd629wFgDtAAAeAsQOWvRTaAfO5j78Y1FtswJQI4ADwossv37sU2rL8xfm9sx5fkuuKgbcevCUCOAC8aNF84KHmCw+FAA4AY4vm8W5rnu+imA8cACLHfOAAEFAME1oxlB4ASoplQitK4ABQ0tGju8F7Ynt7tL1NBHAAKOn06XLbm0IAB4CSJv3Ci25vCgEcAEqKpT94rQBuZr9hZg+a2QNm9jEze0mojAFArGLpD145gJvZJZI+KOmwu79G0rKk94bKGADEbGNDeuwxaWdn9LOLwTx1q1AOSDrPzA5IWpH0P/WzBAAoonIAd/dvS/oTSaclfUfS/7r7Z2b3M7MjZrZpZptbW1vVcwoAOEedKpRXSLpO0hWSXiXpfDO7YXY/dz/h7ofd/fDa2lr1nAIAzlGnCuXtkv7b3bfc/XlJn5D0k2GyBQBYpE4APy3px81sxcxM0tskPRwmWwCARerUgd8r6S5JX5H0tfGxTgTKFwBggVqTWbn7bZJuC5QXAEAJjMQEgEQRwAEgUQRwAEkLvbBCDAs1FMWCDgCSFXphhVgWaiiKNTEBJGt9fRRkZw0Go/lJuj5eKKyJCaB3Qi+sEMtCDUURwAEkK/TCCrEs1FAUARxAskIvrBDLQg1FEcABJCv0wgqxLNRQFI2YABA5GjEBoGcI4ACQKAI4gOSlNHoyJEZiAkhaaqMnQ6IEDiBpR4/uBu+J7e3R9r4jgAOIRpWqkNRGT4ZEAAcQhUlVyKlTkvtuVciiIJ7a6MmQCOAAopBXFXLLLfNL5amNngyJAA4gCnlVHk89Nb9UntroyZAI4ACicOGFxfbLaqDc2BhN97qzM/qZFbz72NWQboQAOjccSs88U3z/sg2Ufe1qSAkcQOeOHpWef774/kVL69PH72NXQwI4gM413eWvr10NCeAAOle2y9/TT4c5fupdDQngADqX1xVwdTV7/7KBt69dDQngADqX1xXw+PEwgbevXQ1Z0AFA1IbDUWPj6dOjkvexY+kH3rIaWdDBzF5uZneZ2dfN7GEz+4k6xwOAWUX6eM/Tx/7fE3X7gR+X9I/u/vNmdkjSyqInAEBb+tr/e6JyCdzMflTSmyXdLknu/py7/yBUxgDsTyFLzH3t/z1RpwrlCklbkj5iZl81s78ys/NndzKzI2a2aWabW1tbNU4HoO+qzkiYp6/9vyfqBPADkt4g6S/c/fWS/k/SrbM7ufsJdz/s7ofX1tZqnA5A34UuMfe1//dEnQD+hKQn3P3e8d93aRTQAaC04XBU4s5StcTc1/7fE5UDuLt/V9LjZvbq8aa3SXooSK4AJGvHTD6TNJtmDIfS9TeYdpSdzvqc42RtHz+2sSE9u33usc5smzZuyM5Haur2Qvk1ScNxD5RHJf1y/SwBSNWOmUzSwtBoNqrkHrv+hoLPyzrOgsfmllJn8pGaWgHc3e+XtKdzOYD9qVIQrvG8/Y6h9ACQKAI4ACSKAA4gGB+nsqzi8/Y7AjiAYJbcXwzi02mP2YZD9z114JWOM/vYogbKhBswJQI40BuxTNq05C6bSZpNWWb2mT1G7nGytk+fI+/xxIO3RAAHeiH0EPQQ+YnhZtJ3BHAgkC6DVkyTNsV2M+kzFnQAApidtlQaDdlua9WXpaXsGgGz0TzabVpfzx4SPxiM5vNGeY0s6ABgpOsScEyTNvV9BsCYEMCBALoOWjFN2hTTzaTvCOBAAF0HrZgW7Y3pZtJ3BHAggBiCVt21I0PmI5abSd/VnY0QgHaD035fPX1iY2P/XnubCOBAIAQttI0qFABIFAEcABJFAAewB0Ph00AAB3COGIbCcwMphgAOJC50sOt6VGkMN5BUEMCBhJUNdkWCfehRpWVvMF3fQFLCZFZAwspMHFV0wq2Qk1FVmeQrpom5YsFkVkAPlSktFy3ZhhxVWqU0nTf9wIUXUi8+iwAOJKzMHCxFg32oofDDYXZJfl5epOwbyMGD0rPPUi8+iwCeMFrq0xbi/1emtFwm2NedV2VSdZJn3iRfWTeQl71Meu65c/ejXlySu7eW3vjGNzrCOHnSfWXl3AX+VlZG2xG/kP+/kyfdBwN3s9HPvGO0+Z4ZDPIXoqxyTstcEHO0fT+QtOkZMZVGzESx6knauvr/DYftTLiV1xApSSdPlj/nfn+/N9aIaWbLZvZVM/t03WPFIoWqia4XEEA9Xf3/2ppyNq+KZDCods4YpuuNUYg68FskPRzgOK2ZF6BTGUTQ9QICqOfCC8ttl4oXLGIogIQOuMwxniOrXqVoknSppM9JequkTy/aP4Y68EX1gHl1d4NBl7neizrwtK2uZr/PVlez9y/6/47pfVG0bh6LqYk6cDO7S9IfSLpA0ofc/V3z9o+hDnxRXVpKgwjaqs9EeGXfZ0XrgPd7XXFfBa8DN7N3SXrS3e9bsN8RM9s0s82tra2qpwtmUd1jSlUTsSyhhfLKvs+K1pnTNrK/1KkDv0bSu83sMUkfl/RWMzs5u5O7n3D3w+5+eG1trcbpwlj0waGxBG0o+z4rGvAX7RdD/TgCyqpXKZskvUUN1YGHrkcrUkdI3R3aUOZ9FqIOPKb6cZSjnDrwqAN4U2+4yQdHcl9e3m2k5I2MmJUZsJO136IGegou8coL4FEP5GmyQabKLGlAyuY1nH70o3weYpbkbISNNciY6RdvMJ3ZNu1oN53ZHm13202aJCAyZeuz59WPMwd3mqIO4I30CBkHYyuYZp+HxWgoa16VAWfzGk7pvZKmqAM4PULSk8pI1jY0eSOrUmKeN5oxpe6zmJJVMd5UiqEXSu4UaUUSFkplJGvTmu7xEXp2PnqoxE0pNmI2ok5VSIuvVapSGska3NR7y8dp+t3mkq4c+G4DfI33YtbxX8xG7pM8/5zu2jHb89y5OeTz0JokGzGRnn37VXwmMOa1qTx6yjL3L326OaloHmcfWypzrEXHQyv2XwCfU2rwjFTkedhFu8WurNJsyJBH+MT+C+BSbi23ZaQXH0dh5523+/vqKn2JgabszwCOUsrMQ33kiPTUU7vbfvjDNnLYvFA9Sig1I6SkAzj9jZtXpltgXweD9L1rJN8v05VsAI/pQ9XnG0mZoNzXwSCFXoOi1WyT/Wb2z2p/2dMOU5e7dnLOMTxZ4UxULXYu2W6EsUxc3/c5Vcp0C4zlfxJaG10j2+p+2df/Ud/1rhthLKW9vlYbTJTpFtjXHihtdI3MWwtzaSnsN7tYPjcII9kAHkt/475/IMoE5b4uPNv0jWk4lJ55Jvuxs2fDVhGW+dz0uWqwN7KGZzaVQi5qHMvQ3/0wdJx5opt9DfLeQ028r1JcHBn5Q+njD+Bz5iQ5K/nOTGp77pKmF53Yz0GzCTG+rnnzmoSc62RakddgPxRMUpJmAC/6rp6XWtDFsm8or87rOv0/Xl0dpVD/7zZL4EWFniwL9RDAIzcdICbLvFH6CatqqTIr8Ie8uWYd/9Ah94MHu7uJUwKPS14AT7YRM6SuG2tm+7SfPZu9X18aRrtStcE5q6fRtLq9jrIaf++4Q/rIR7prEM5quDUbvUdp0IxIVlRvKsVYAl+0incb9aVFv0JT+qmnaqmySB11H6sWphf/nn0NqNJrl6hCyZb3oV5dba8eukiA4ANTX5keGNM37tXV/X1zpTqle3kBPO4qFPf87XmPFXn+lLyvz0891d4Anby+ucvL/epP3bUi/dSzpmh45hnp0KH84/ZhsNI8fR/rkLK4A7iUXeCZ91jWfnOUHfjTxJs2b6DInXeOhlE/9ljx4N11fX7sNjZGr2fe65pV3/3889IFF+wG/tXVUdovN9dYBs0hQ1axvKkUciBPKHlfq+d9bW6iPjxEfTvdD+uj+9xevK+6pyTrwFuSFTyb7jrWBOoq64vlNYxtwFFs+dlvCOAVTLfCx/ChXoTSY7YywadsaXPesasGPUq8mEUAr6HtwFj1gx9L6TEmVYJh0dd/URfUqkGY/yNmBQ/gki6T9HlJD0l6UNIti56TagBv8wNVp186Jbe9mvzfzTt2nfPyTQqzmgjgF0t6w/j3CyR9U9LV856TagBvMzDW7Zd+8827Q/GXl0d/72dNBsN5x65z3hA3Heqs+6XxKhRJn5T0jnn7JBfApz49s7MenpUy9zsnFTjubJo9T5FU5LmZeSua50X7zbmeUqnseQvk9ew4zX1NKl5L1jHPSrVL4HULDHwT65+8AB6kH7iZrUt6vaR7Mx47YmabZra5tbUV4nTtsHPXD7eZtDTZZ2a/ecfI3TbnPEVSkecWzsfs9kX7LbieUqaPVTR/Cx4r9JpUvJa84z56ymotAlF3YYy+rxKFXbXXxDSzl0r6V0nH3P0T8/YNuSZm40IFptnXN2TAa8p0nufl1z389UzOvei8WerkJfS1uGs4HAXN06dHg16OHWtnwE9b62uiPXlrYh6oedCDku6WNFwUvPvIlVO6BTQK1l2M0Lz88uyFixk52T+Vq1DMzCTdLulhd/9wuCwBqKOvi0tjrzp14NdIep+kt5rZ/eP0zkD5ip6PU1k7Gc+reqxYxJT3rNd2v+nr4tLYq3IAd/cvuru5+2vd/XXjdE/IzHVqqhLRc9KVA8+vj505xsSVA889Xqvy8j27fcF+w5OLryfv8T3XPX2uovmbkpeXhdW+k2PWbA/ac7wOLZq0C/0Q/2yEXRr3wvrbk66XrriWtJsuWPHdr6R5Hc0ynD4tLevcYy3LdcCCdcbbk4YnXesD15KNfg5Pen6+57wOWfsdPbr3epbkumKwu+8Vg72PZ+1X5rxZsvKyLN+90Rb5P4V4zYGW9CaANzmNasivpG1PzZk1v/WRI6PtIV6zInNFz5uCN2S9LPNWY9/J6hzeVGpqIE9KAxfazmvTKw4VGbAyLw8hMYcI+kpJrshTUEoDF9puYGp6xaEiPR7y9jl+vNy5QuQF6JWsqN5UaqoEzuQ/ey2aCjcvVXnNisy70dbcHMwBgj5STgm89kjMMpoaibm+nj1wYTAYtcDvN5N679kS9sTKinTeeaNS+Kz9+poBMcsbidmLKpQYvjrHtBZlVpXSxKTK5vjx7l8zADVlFcubSk3ORtjlV+euG1Fnr71o9Ujs1Q2x5w9oi1iRpzld9n7IunnktQmk1Buj65tiG7hBoai8AN6LKpSuNdn/OKtqZnrbjTfurS5x3zuxXmrVIyn1LKpiXv98oKheNGJ2ralG1KzGyEOHRh/4559f/PzBoP2pTEPp+5SoNLyjjF43YnatqUbUrFLoc88VC96rq3HMhVG1cbftEattY9QoQiCAB9DU4Jw6H+Znn+3+6/j73y+9733Vqgli6FnUpL7foNCSrIrxplJfGzGbUmUgTiyNlidPzm9MjWnwTxf2QyMtwhG9UNJz8817g+ChQ+4HDxYL4F2ORF1084k1eLV50+jzDQph5QVwGjEjldWAaSbddJN0zTXnrrV45kx8oyrzGiElaXlZOnt27/auG/CyXvOVFRZDQPfyGjEJ4JEq00shxsCTl/95uu5hQs8QxIpeKIkp00thuhFVGpVwJ32mu2rIzGqEXKTrBjx6hiA1BPBIle2lsLGxGzQn1RNdDg6ZvaksEkMPE3qGIDUE8EhV6UYX2+jFybqMs6NCp8W06G7fuy6ifwjgkarStzzWKoC8Euxg0P1Ao2ms5o7U0IjZI7E2wsXYyAqkhEbMfSDWKgBKtkAzDnSdAYQzCYjTfcRjmcRqYyOOfAB9QgDvGQIlsH9QhQIAiSKAA0CiagVwM7vWzL5hZo+Y2a2hMgUAWKxyADezZUl/LulnJV0t6XozuzpUxgAA89Upgb9J0iPu/qi7Pyfp45KuC5MtAMAidQL4JZIen/r7ifG2c5jZETPbNLPNra2tGqcDAExrvBHT3U+4+2F3P7y2ttb06QBg36gTwL8t6bKpvy8dbwMAtKBOAP+ypKvM7AozOyTpvZI+FSZbAIBFKo/EdPcXzOwDkv5J0rKkO9z9wWA5AwDMVWsovbvfI+meQHkBAJTASEw0ajgcTXO7tDT62dUSb0AfMZkVGjM7D/hkiTeJCbeAECiBozGxLfEG9A0BHI2JdYk3oC8I4GgMq7wDzSKAozGxLvEG9AUBHI1hLUygWfRCQaNY4g1oDiVwAEgUARwAEkUAB4BEEcABIFEEcABIlLl7eycz25J0qsCuF0n6fsPZaRPXE7++XRPXE7ey1zNw9z1LmrUawIsys013P9x1PkLheuLXt2vieuIW6nqoQgGARBHAASBRsQbwE11nIDCuJ359uyauJ25BrifKOnAAwGKxlsABAAsQwAEgUdEGcDP7fTP7LzO738w+Y2av6jpPdZjZH5vZ18fX9Pdm9vKu81SHmf2CmT1oZjtmlmz3LjO71sy+YWaPmNmtXeenLjO7w8yeNLMHus5LCGZ2mZl93sweGr/fbuk6T3WY2UvM7D/M7D/H1/O7tY4Xax24mb3M3Z8Z//5BSVe7+00dZ6syM/tpSf/i7i+Y2R9Jkrv/VsfZqszMfkzSjqS/lPQhd9/sOEulmdmypG9KeoekJyR9WdL17v5QpxmrwczeLOmMpL9x99d0nZ+6zOxiSRe7+1fM7AJJ90l6T6r/IzMzSee7+xkzOyjpi5JucfcvVTletCXwSfAeO19SnHeagtz9M+7+wvjPL0m6tMv81OXuD7v7N7rOR01vkvSIuz/q7s9J+rik6zrOUy3u/gVJT3edj1Dc/Tvu/pXx789KeljSJd3mqjofOTP+8+A4VY5t0QZwSTKzY2b2uKQNSb/TdX4C+hVJ/9B1JqBLJD0+9fcTSjg49J2ZrUt6vaR7u81JPWa2bGb3S3pS0mfdvfL1dBrAzeyfzeyBjHSdJLn7UXe/TNJQ0ge6zGsRi65nvM9RSS9odE1RK3I9QBvM7KWS7pb06zPfzpPj7mfd/XUafQt/k5lVrurqdEk1d397wV2Hku6RdFuD2alt0fWY2S9Jepekt3msjQ9TSvx/UvVtSZdN/X3peBsiMq4rvlvS0N0/0XV+QnH3H5jZ5yVdK6lSo3O0VShmdtXUn9dJ+npXeQnBzK6V9JuS3u3u213nB5JGjZZXmdkVZnZI0nslfarjPGHKuNHvdkkPu/uHu85PXWa2NumBZmbnadSAXjm2xdwL5W5Jr9aop8MpSTe5e7KlIzN7RNKPSHpqvOlLifeq+TlJfyZpTdIPJN3v7j/Tba7KM7N3SvpTScuS7nD3Yx1nqRYz+5ikt2g0Xen3JN3m7rd3mqkazOynJP2bpK9pFAsk6bfd/Z7uclWdmb1W0p0avd+WJP2du/9e5ePFGsABAPNFW4UCAJiPAA4AiSKAA0CiCOAAkCgCOAAkigAOAIkigANAov4fte50rWa0ZPwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhyG0etubLJ4",
        "colab_type": "text"
      },
      "source": [
        "## Direct use of GBRT using sklearn's GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds9kb6UUgI44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "4b524d12-e64c-49d1-a715-0c9e07a6bb27"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
        "gbrt.fit(X, y)\n",
        "y_pred = gbrt.predict(X)\n",
        "\n",
        "# plot values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, y, 'bo')\n",
        "plt.plot(X, y_pred, 'ro')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr35Ix3abKr8",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters:\n",
        "Like the RandomForestRegressor class, it has hyperparameters to control the growth of Decision Trees (e.g., max_depth, min_samples_leaf, and so on), as well as hyperparameters to control the ensemble training, such as the number of\n",
        "trees (n_estimators).\n",
        "\n",
        "The learning_rate hyperparameter scales the contribution of each tree. If you set it to a low value, such as 0.1, you will need more trees in the ensemble to fit the training set, but the predictions will usually generalize better. This is a regularization technique called shrinkage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7FY8GPD5UMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "bba1c15f-2ccf-4de1-eabe-82a9b59320a2"
      },
      "source": [
        "# exanple with low learning rate(0.1)(will require more decision trees(n_estimators) but will fit better)\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=30, learning_rate=0.1)\n",
        "gbrt.fit(X, y)\n",
        "y_pred = gbrt.predict(X)\n",
        "\n",
        "# plot values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, y, 'bo')\n",
        "plt.plot(X, y_pred, 'ro')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_sgs3lR59oU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "In order to find the optimal number of trees, you can use early stopping. A simple way to implement this is to use the staged_predict() method: it\n",
        "returns an iterator over the predictions made by the ensemble at each stage of training(with one tree, two trees, etc.). \n",
        "\n",
        "### Finding optimal number of trees by checking all combinations\n",
        "The following code trains a GBRT ensemble with 120 trees, then measures the validation error at each stage of training to find the optimal number of trees,and finally trains another GBRT ensemble using the optimal number of trees:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSfTlUNt6mio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "c617f825-17cf-4e37-9c5b-7923a4ee975b"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "errors = [mean_squared_error(y_true=y_val, y_pred=y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
        "errors\n",
        "\n",
        "# finding n_estimator with min error\n",
        "n_estimators_best = np.argmin(errors)\n",
        "n_estimators_best, errors[n_estimators_best]\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=n_estimators_best)\n",
        "gbrt_best.fit(X_train, y_train)\n",
        "\n",
        "y_pred_best = gbrt_best.predict(X)\n",
        "\n",
        "# plot values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, y, 'bo')\n",
        "plt.plot(X, y_pred_best, 'ro')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F5M_1Zo9NhJ",
        "colab_type": "text"
      },
      "source": [
        "### Finding optimal number of tree by actually stopping when one found\n",
        "You can do so by **setting warm_start=True**, which makes Scikit-\n",
        "Learn keep existing trees when the fit() method is called, allowing incremental\n",
        "training. The following code stops training when the validation error does not\n",
        "improve for five iterations in a row:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTqKSOaX7Yv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7983dab-8179-42c0-e2fa-fdd2d723f47f"
      },
      "source": [
        "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
        "\n",
        "min_val_err = float(\"inf\")\n",
        "error_going_up = 0\n",
        "final_n_estimators = 1\n",
        "y_train=y_train.reshape(-1)\n",
        "y_val=y_val.reshape(-1)\n",
        "\n",
        "for n_estimators in range(1,120):\n",
        "    gbrt.n_estimators = n_estimators\n",
        "    gbrt.fit(X_train, y_train)\n",
        "    y_pred = gbrt.predict(X_val)\n",
        "    val_err = mean_squared_error(y_true=y_val, y_pred=y_pred)\n",
        "    if val_err < min_val_err:\n",
        "        min_val_err = val_err\n",
        "        final_n_estimators = n_estimators\n",
        "        error_going_up = 0\n",
        "    else:\n",
        "        error_going_up += 1\n",
        "        if error_going_up == 5:\n",
        "            break # early stopping\n",
        "\n",
        "print(final_n_estimators, min_val_err, y_val.shape, y_pred.shape)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44 0.7882314315716833 (25,) (25,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJrnFvmWB4V6",
        "colab_type": "text"
      },
      "source": [
        "## Stochastic gradient boosting\n",
        "\n",
        "The GradientBoostingRegressor class also supports a **subsample** hyperparameter, which specifies the fraction of training instances to be used for training each tree. For example, if subsample=0.25, then each tree is trained on 25% of the training instances, selected randomly. This trades a higher bias for a lower variance. It also speeds up training considerably."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_xZWGpFCLsZ",
        "colab_type": "text"
      },
      "source": [
        "# XGBoost (Extreme Gradient Boosting)\n",
        "\n",
        "An optimized implementation of Gradient Boosting. Implemented by a seperate library XGBoost. Aims at being extremely fast, scalable\n",
        "and portable.\n",
        "\n",
        "This is widely used in kaggle competetions in many winning entries today."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1oN-wCQCtYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65cbd604-751e-4dc2-97b4-e9b61d4f34ab"
      },
      "source": [
        "import xgboost\n",
        "\n",
        "xgb_reg = xgboost.XGBRegressor()\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "y_pred = xgb_reg.predict(X_val)\n",
        "mean_squared_error(y_true=y_val, y_pred=y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14:02:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8642704432666407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "743HNJRYDl9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "2260d8af-7444-4b19-eb75-e41e559f5b15"
      },
      "source": [
        "# XGBoost also offers several nice features, such as automatically taking care of early stopping:\n",
        "\n",
        "xgb_reg.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
        "y_pred = xgb_reg.predict(X_val)\n",
        "mean_squared_error(y_true=y_val, y_pred=y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14:02:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:3.48488\n",
            "Will train until validation_0-rmse hasn't improved in 2 rounds.\n",
            "[1]\tvalidation_0-rmse:3.18731\n",
            "[2]\tvalidation_0-rmse:2.92618\n",
            "[3]\tvalidation_0-rmse:2.68454\n",
            "[4]\tvalidation_0-rmse:2.47934\n",
            "[5]\tvalidation_0-rmse:2.29512\n",
            "[6]\tvalidation_0-rmse:2.12897\n",
            "[7]\tvalidation_0-rmse:1.9815\n",
            "[8]\tvalidation_0-rmse:1.83621\n",
            "[9]\tvalidation_0-rmse:1.71008\n",
            "[10]\tvalidation_0-rmse:1.60778\n",
            "[11]\tvalidation_0-rmse:1.5127\n",
            "[12]\tvalidation_0-rmse:1.43277\n",
            "[13]\tvalidation_0-rmse:1.35818\n",
            "[14]\tvalidation_0-rmse:1.30087\n",
            "[15]\tvalidation_0-rmse:1.2457\n",
            "[16]\tvalidation_0-rmse:1.20058\n",
            "[17]\tvalidation_0-rmse:1.15412\n",
            "[18]\tvalidation_0-rmse:1.12235\n",
            "[19]\tvalidation_0-rmse:1.09062\n",
            "[20]\tvalidation_0-rmse:1.06179\n",
            "[21]\tvalidation_0-rmse:1.0392\n",
            "[22]\tvalidation_0-rmse:1.01556\n",
            "[23]\tvalidation_0-rmse:0.995664\n",
            "[24]\tvalidation_0-rmse:0.980901\n",
            "[25]\tvalidation_0-rmse:0.967763\n",
            "[26]\tvalidation_0-rmse:0.957342\n",
            "[27]\tvalidation_0-rmse:0.947378\n",
            "[28]\tvalidation_0-rmse:0.940609\n",
            "[29]\tvalidation_0-rmse:0.931371\n",
            "[30]\tvalidation_0-rmse:0.925255\n",
            "[31]\tvalidation_0-rmse:0.917953\n",
            "[32]\tvalidation_0-rmse:0.911166\n",
            "[33]\tvalidation_0-rmse:0.905376\n",
            "[34]\tvalidation_0-rmse:0.903387\n",
            "[35]\tvalidation_0-rmse:0.899955\n",
            "[36]\tvalidation_0-rmse:0.895762\n",
            "[37]\tvalidation_0-rmse:0.893746\n",
            "[38]\tvalidation_0-rmse:0.893297\n",
            "[39]\tvalidation_0-rmse:0.892524\n",
            "[40]\tvalidation_0-rmse:0.889542\n",
            "[41]\tvalidation_0-rmse:0.889666\n",
            "[42]\tvalidation_0-rmse:0.888101\n",
            "[43]\tvalidation_0-rmse:0.88726\n",
            "[44]\tvalidation_0-rmse:0.885178\n",
            "[45]\tvalidation_0-rmse:0.883721\n",
            "[46]\tvalidation_0-rmse:0.882434\n",
            "[47]\tvalidation_0-rmse:0.881738\n",
            "[48]\tvalidation_0-rmse:0.882784\n",
            "[49]\tvalidation_0-rmse:0.881781\n",
            "Stopping. Best iteration:\n",
            "[47]\tvalidation_0-rmse:0.881738\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7774615832982817"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FeyjSmzlejY",
        "colab_type": "text"
      },
      "source": [
        "# Sampling\n",
        "\n",
        "Based on a simple idea: instead of using trivial functions\n",
        "(such as hard voting) to aggregate the predictions of all predictors in an ensemble, we train a model to perform this aggregation.\n",
        "\n",
        "Example: Each of the bottom three predictors predicts a different value (3.1, 2.7, and 2.9), and then the final predictor(called a blender, or a meta learner) takes these predictions as inputs and makes the final prediction (3.0).\n",
        "\n",
        "To train the blender, a common approach is to use a hold-out set. First, the training set is split in two subsets. The first subset is used to train the\n",
        "predictors in the first layer. Next, the first layer predictors are used to make predictions on the second (held-out) set. This ensures that the predictions are “clean,” since the predictors never saw these instances during training. Now for each instance in the hold-out set there are three predicted values. We can create a new training set using these predicted values as input features (which makes this new training set three-dimensional),\n",
        "and keeping the target values. The blender is trained on this new training set, so it learns to predict the target value given the first layer’s predictions.\n",
        "\n",
        "It is actually possible to train several different blenders this way (e.g., one using Linear Regression, another using Random Forest Regression, and so on): we get a whole layer of blenders. The trick is to split the training set into three subsets: the first one is used to train the first layer, the second one is used to create the training set used to train the second layer (using predictions made by the predictors of the first layer), and the third one is used to create the training set to train the third layer (using predictions\n",
        "made by the predictors of the second layer). Once this is done, we can make\n",
        "a prediction for a new instance by going through each layer sequentially."
      ]
    }
  ]
}