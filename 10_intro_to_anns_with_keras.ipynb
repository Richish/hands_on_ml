{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_intro_to_anns_with_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNWqUvRhaaOU1AJ/NGSPoKr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Richish/hands_on_ml/blob/master/10_intro_to_anns_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSqTeFKaCj1O"
      },
      "source": [
        "Why is this wave of interest in anns different than the last one-\n",
        "1. There is now a huge quantity of data available to train neural networks, and\n",
        "ANNs frequently outperform other ML techniques on very large and complex\n",
        "problems.\n",
        "2. Increase in compute today.\n",
        "3. Some theoretical limitations of ANNs have turned out to be benign in practice.\n",
        "For example, many people thought that ANN training algorithms were doomed\n",
        "because they were likely to get stuck in local optima, but it turns out that this is\n",
        "rather rare in practice (or when it is the case, they are usually fairly close to the\n",
        "global optimum)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgXJTT5xCj4Y"
      },
      "source": [
        "Biological brains of mammals- vast network of billions of neurons. each neuron Typically connected to thousands of other neurons. Highly complex computations can be performed by a vast network of fairly simple neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKFDdckFCj7L"
      },
      "source": [
        "Artificial neuron- It has one or more binary (on/off) inputs and one binary output. The artificial neuron simply activates its output when more than a certain number of its inputs are active. McCulloch and Pitts showed that even with such a simplified model(with just- identity, and, or, xor operations) it is possible to build a network of\n",
        "artificial neurons that computes any logical proposition you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o--EZRizCj9w"
      },
      "source": [
        "# The Perceptron\n",
        "It is one of the simplest ANN architectures, invented in 1957 by Frank\n",
        "Rosenblatt. It is based on a slightly different artificial neuron called\n",
        "From Biological to Artificial Neurons a threshold logic unit (TLU), or sometimes a linear threshold unit (LTU): the inputs and output are now numbers (instead of binary on/off values) and each input connection is associated with a weight. The TLU computes a weighted sum of its inputs\n",
        "(z = w1 x1 + w2 x2 + ⋯ + wn xn = xT w), then applies a step function to that sum and outputs the result: hw(x) = step(z), where z = xT w.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Mf2Ak_sCkAR"
      },
      "source": [
        "The most common step function used in Perceptrons is the Heaviside step function\n",
        "heaviside(z) = 0 if z<0 else 1\n",
        "\n",
        "A single TLU can be used for simple linear binary classification. It computes a linear combination of the inputs and if the result exceeds a threshold, it outputs the positive class or else outputs the negative class.\n",
        "\n",
        "A Perceptron is simply composed of a single layer of TLUs, with each TLU connected\n",
        "to all the inputs. When all the neurons in a layer are connected to every neuron in the\n",
        "previous layer (i.e., its input neurons), it is called a fully connected layer or a dense\n",
        "layer. To represent the fact that each input is sent to every TLU, it is common to draw\n",
        "special passthrough neurons called input neurons: they just output whatever input\n",
        "they are fed. All the input neurons form the input layer. Moreover, an extra bias feature is generally added (x0 = 1): it is typically represented using a special type of neuron\n",
        "called a bias neuron, which just outputs 1 all the time. \n",
        "\n",
        "A Perceptron with two inputs and three outputs can classify instances simultaneously into three different binary classes, which makes it a multioutput\n",
        "classifier.\n",
        "\n",
        "hW, b( X) = ϕ(XW + b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49_aPiuCCkC-"
      },
      "source": [
        "How are perceptrons trained- More specifically, the Perceptron is fed one\n",
        "training instance at a time, and for each instance it makes its predictions. For every output neuron that produced a wrong prediction, it reinforces the connection weights from the inputs that would have contributed to the correct prediction.\n",
        "\n",
        "wi, j next step = wi, j + η (y{j} − ÿ{j}).x{i}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THnWeaKMCkFl"
      },
      "source": [
        "The decision boundary of each output neuron is linear, so Perceptrons are incapable\n",
        "of learning complex patterns (just like Logistic Regression classifiers). However, if the\n",
        "training instances are linearly separable, Rosenblatt demonstrated that this algorithm\n",
        "would converge to a solution.7 This is called the Perceptron convergence theorem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajuuRRa-CkIH"
      },
      "source": [
        "## Perceptron with sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nHcqGoUKc4s",
        "outputId": "4c462ff2-0d2a-4ae0-a21b-dd2c75c90693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, (2, 3)] # petal length, petal width\n",
        "y = (iris.target == 0).astype(np.int) # Iris Setosa?\n",
        "per_clf = Perceptron()\n",
        "per_clf.fit(X, y)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
              "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
              "           validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYNXR-HHK1V1",
        "outputId": "7cb53d8e-c79d-4ff4-a2c5-5ede7c44a5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = per_clf.predict([[2, 0.5]])\n",
        "\n",
        "y_pred"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFIyjgYtCkK6"
      },
      "source": [
        "### sklearn's Perceptron vs SGDClassifier\n",
        "Scikit-Learn’s Perceptron class is equivalent\n",
        "to using an SGDClassifier with the following hyperparameters: loss=\"perceptron\",\n",
        "learning_rate=\"constant\", eta0=1 (the learning rate), and penalty=None (no regularization).\n",
        "\n",
        "However, contrary to Logistic Regression classifiers, Perceptrons do not output a class probability; rather, they just make predictions based on a hard threshold. This is one of the good reasons to prefer Logistic Regression over Perceptrons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea5W_U6bCkNg"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFx36JtCkQI"
      },
      "source": [
        "## Limitations of perceptrons:\n",
        "a number of serious weaknesses of Perceptrons, in particular the fact that\n",
        "they are incapable of solving some trivial problems (e.g., the Exclusive OR (XOR) classification problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvYDiDz1CkSo"
      },
      "source": [
        "# Multi-Layer perceptrons (MLP)\n",
        "some of the limitations of Perceptrons can be eliminated by\n",
        "stacking multiple Perceptrons. The resulting ANN is called a Multi-Layer Perceptron (MLP). In particular, an MLP can solve the XOR problem.\n",
        "\n",
        "An MLP is composed of one (passthrough) input layer, one or more layers of TLUs,\n",
        "called hidden layers, and one final layer of TLUs called the output layer. The layers close to the input layer are usually called the lower layers,\n",
        "and the ones close to the outputs are usually called the upper layers. Every layer except the output layer includes a bias neuron and is fully connected to the next layer.\n",
        "\n",
        "When an ANN contains a deep stack of hidden layers8, it is called a deep neural network(DNN)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FacLGPryMGVQ"
      },
      "source": [
        "## Multi-Layer Perceptron and Backpropagation:\n",
        "Backpropagation: it is simply Gradient Descent using an efficient technique for computing the gradients automatically: in just two passes through the network (one forward, one backward), the backpropagation algorithm is able to compute the gradient of the network’s error with regards to every single model parameter. In other words, it can find out how each connection weight and\n",
        "each bias term should be tweaked in order to reduce the error. Once it has these gradients, it just performs a regular Gradient Descent step, and the whole process is repeated until the network converges to the solution.\n",
        "\n",
        "Autodiff- Automatically computing gradients is called automatic differentiation,\n",
        "or autodiff. There are various autodiff techniques, with different\n",
        "pros and cons. The one used by backpropagation is called\n",
        "reverse-mode autodiff. It is fast and precise, and is well suited when\n",
        "the function to differentiate has many variables (e.g., connection\n",
        "weights) and few outputs (e.g., one loss)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coD0o3dsMGYE"
      },
      "source": [
        "## Backpropagation in detail:\n",
        "1. It handles one mini-batch at a time (for example containing 32 instances each), and it goes through the full training set multiple times. Each pass is called an epoch.\n",
        "2. Each mini-batch is passed to the network’s input layer, which just sends it to the first hidden layer. The algorithm then computes the output of all the neurons in this layer (for every instance in the mini-batch). The result is passed on to the next layer, its output is computed and passed to the next layer, and so on until we get the output of the last layer, the output layer. This is the forward pass: it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backward pass.\n",
        "3. Next, the algorithm measures the network’s output error (i.e., it uses a loss function that compares the desired output and the actual output of the network, and returns some measure of the error).\n",
        "4. Then it computes how much each output connection contributed to the error.\n",
        "This is done analytically by simply **applying the chain rule** (perhaps the most fundamental rule in calculus), which makes this step fast and precise.\n",
        "5. The algorithm then measures how much of these error contributions came from\n",
        "each connection in the layer below, again using the chain rule—and so on until\n",
        "the algorithm reaches the input layer. As we explained earlier, this reverse pass efficiently measures the error gradient across all the connection weights in the network by propagating the error gradient backward through the network (hence the name of the algorithm).\n",
        "6. Finally, the algorithm performs a Gradient Descent step to tweak all the connection weights in the network, using the error gradients it just computed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIZBTvVeMGau"
      },
      "source": [
        "**It is important to initialize all the hidden layers’ connection weights\n",
        "randomly, or else training will fail.** For example, if you initialize all\n",
        "weights and biases to zero, then all neurons in a given layer will be\n",
        "perfectly identical, and thus backpropagation will affect them in\n",
        "exactly the same way, so they will remain identical. In other words,\n",
        "despite having hundreds of neurons per layer, your model will act\n",
        "as if it had only one neuron per layer: it won’t be too smart. If\n",
        "instead you randomly initialize the weights, you break the symmetry\n",
        "and allow backpropagation to train a diverse team of neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUFLuBAmMGdR"
      },
      "source": [
        "## Step function in MLP:\n",
        "\n",
        "In order for this algorithm to work properly, the authors made a key change to the MLP’s architecture: they replaced the step function with the logistic function, σ(z) = 1 / (1 + exp(–z)). This was essential because the step function contains only flat segments, so there is no gradient to work with (Gradient Descent cannot move on a flat surface), while the logistic function has a well-defined nonzero derivative everywhere, allowing Gradient Descent to make some progress at every step. In fact, the backpropagation algorithm works well with many other activation functions, not just the logistic function. Two other popular activation functions are:\n",
        "\n",
        "### The hyperbolic tangent function tanh(z) = 2σ(2z) – 1\n",
        "Just like the logistic function it is S-shaped, continuous, and differentiable, but its output value ranges from –1 to 1 (instead of 0 to 1 in the case of the logistic function), which tends to make each layer’s output more or less centered around 0 at the beginning of training. This often helps speed up convergence.\n",
        "\n",
        "### The Rectified Linear Unit function: ReLU(z) = max(0, z)\n",
        "It is continuous but unfortunately not differentiable at z = 0 (the slope changes abruptly, which can make Gradient Descent bounce around), and its derivative is 0 for z < 0. However, in practice it works very well and has the advantage of being fast to compute11. Most importantly, the fact that it does not have a maximum output value also helps reduce some issues during Gradient Descent.\n",
        "\n",
        "### Why do we need step function:\n",
        "If you chain several linear transformations, all you get is a linear transformation. For example, say f(x) = 2 x + 3 and g(x) = 5 x - 1, then chaining these two linear functions gives you another linear function: f(g(x)) = 2(5 x - 1) + 3 = 10 x + 1. So if you don’t have some non-linearity between layers, then even a deep stack of layers is equivalent to a single layer: you cannot solve very complex problems with that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHnYUkKzMGf1"
      },
      "source": [
        "## Regresssion MLPs\n",
        "If you want to predict a single value (e.g.,\n",
        "the price of a house given many of its features), then you just need a single output\n",
        "neuron: its output is the predicted value. For multivariate regression (i.e., to predict\n",
        "multiple values at once), you need one output neuron per output dimension.\n",
        "\n",
        "## Choice of activation function:\n",
        "In general, when building an MLP for regression, you do not want to use any activation\n",
        "function for the output neurons, so they are free to output any range of values.\n",
        "However, if you want to guarantee that the output will always be positive, then you\n",
        "can use the ReLU activation function, or the softplus activation function in the output\n",
        "layer. Finally, if you want to guarantee that the predictions will fall within a given\n",
        "range of values, then you can use the logistic function or the hyperbolic tangent, and\n",
        "scale the labels to the appropriate range: 0 to 1 for the logistic function, or –1 to 1 for\n",
        "the hyperbolic tangent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6LjP4T8MGib"
      },
      "source": [
        "### Choice of loss function:\n",
        "The loss function to use during training is typically the mean squared error, but if you have a lot of outliers in the training set, you may prefer to use the mean absolute error instead. Alternatively, you can use the Huber loss, which is a combination of both.\n",
        "\n",
        "The Huber loss is quadratic when the error is smaller than a threshold\n",
        "δ (typically 1), but linear when the error is larger than δ. This\n",
        "makes it less sensitive to outliers than the mean squared error, and\n",
        "it is often more precise and converges faster than the mean absolute\n",
        "error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLnodWeIMGmA"
      },
      "source": [
        "## Typical Regression MLP Architecture\n",
        "1. input neurons - One per input feature (e.g., 28 x 28 = 784 for MNIST)\n",
        "2. hidden layers - Depends on the problem. Typically 1 to 5.\n",
        "3. neurons per hidden layer - Depends on the problem. Typically 10 to 100.\n",
        "4. output neurons - 1 per prediction dimension\n",
        "5. Hidden activation - ReLU (or SELU, see Chapter 11)\n",
        "6. Output activation - None or ReLU/Softplus (if positive outputs) or Logistic Tanh (if bounded outputs)\n",
        "7. Loss function - MSE or MAE/Huber (if outliers).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyts1ec4MGo-"
      },
      "source": [
        "## Classification MLPs\n",
        "\n",
        "### Binary classification:\n",
        "Needs a single output neuron using the logistic activation function: the output will be a number between 0 and 1, which you can interpret as the estimated probability of the positive class.\n",
        "\n",
        "### Multi-label classification:\n",
        "For example, you could have an email classification system that predicts whether each incoming email is ham or spam, and simultaneously predicts whether it is an urgent or non-urgent email. In this case, you would need two output neurons, both using the logistic activation function. More generally, you would dedicate one output neuron for each positive class. Note that the output probabilities do not necessarily add up to one. This lets the model output any combination of labels: you can have non-urgent ham, urgent ham, non-urgent spam, and perhaps even urgent spam (although that would probably be an error).\n",
        "\n",
        "### Multi-class classsification:\n",
        "If each instance can belong only to a single class, out of 3 or more possible classes (e.g., classes 0 through 9 for digit image classification), then you need to have one output neuron per class, and you should use the softmax activation function for the whole output layer. The softmax function will ensure that all the estimated probabilities are between 0 and 1 and that they add\n",
        "up to one (which is required if the classes are exclusive). This is called multiclass classification.\n",
        "\n",
        "### Loss function for classification:\n",
        "Since we are predicting probability distributions, the cross-entropy (also called the log loss) is generally a good choice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgL63P7CMGrl"
      },
      "source": [
        "# Implementing MLPs with keras\n",
        "\n",
        "## Keras:\n",
        "To perform the heavy computations required by neural networks, keras-team relies on a computation backend. At the present, you can choose from three popular open source deep learning libraries: TensorFlow, Microsoft Cognitive Toolkit (CNTK) or Theano.\n",
        "\n",
        "TensorFlow itself now comes bundled with its own Keras implementation called tf.keras. It only supports TensorFlow as the backend, but it has\n",
        "the advantage of offering some very useful extra features: for\n",
        "example, it supports TensorFlow’s Data API which makes it quite easy to load and preprocess data efficiently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABWlv_Jkp9qY",
        "outputId": "82f91803-a2b7-4c78-b206-92276114fff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "tf.__version__, keras.__version__"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.3.0', '2.4.0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zNqbCjKMGuV"
      },
      "source": [
        "## Building an image classifier using sequential api of keras:\n",
        "\n",
        "Using Fashion MNIST data.\n",
        "It has the exact same format as\n",
        "MNIST (70,000 grayscale images of 28×28 pixels each, with 10 classes), but the\n",
        "images represent fashion items rather than handwritten digits, so each class is more\n",
        "diverse and the problem turns out to be significantly more challenging than MNIST.\n",
        "For example, a simple linear model reaches about 92% accuracy on MNIST, but only\n",
        "about 83% on Fashion MNIST.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r698E38dqUuW",
        "outputId": "8cfa7579-dde3-4308-ed77-3983ec05a7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Loading data using keras\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "help(fashion_mnist)\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train_full.shape, X_train_full.dtype"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on package tensorflow.keras.datasets.fashion_mnist in tensorflow.keras.datasets:\n",
            "\n",
            "NAME\n",
            "    tensorflow.keras.datasets.fashion_mnist - Fashion-MNIST dataset.\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/keras/datasets/fashion_mnist/__init__.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), dtype('uint8'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqm49T03MGw3"
      },
      "source": [
        "### Loading MNIST or Fashion MNIST using Keras vs Scikit-Learn, one\n",
        "Important difference is that every image is represented as a 28×28 array rather than a 1D array of size 784. Moreover, the pixel intensities are represented as integers (from0 to 255) rather than floats (from 0.0 to 255.0).\n",
        "\n",
        "Note that the dataset is already split into a training set and a test set, but there is no validation set, so let’s create one. Moreover, since we are going to **train the neural network using Gradient Descent, we must scale the input features***. For simplicity, we just\n",
        "scale the pixel intensities down to the 0-1 range by dividing them by 255.0 (this also\n",
        "converts them to floats):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qWH-ZmjriQe",
        "outputId": "3c0acf96-10b9-4435-8ec1-354a5dd9d6b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "# we have to define what cleass each number in y represent\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "class_names[y_train[0]]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Coat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_8rcaVRtRlp"
      },
      "source": [
        "### Creating the Model Using the Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEjEpJ6QtNZG",
        "outputId": "2207abd6-07f6-4ee6-96c3-1c86aa42fed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Creating the Model Using the Sequential API\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=[28,28])) # alternativel can use - model.add(keras.layers.InputLayer(shape=[28,28]))\n",
        "model.add(Dense(units=300, activation=\"relu\"))\n",
        "model.add(Dense(units=100, activation=\"relu\"))\n",
        "model.add(Dense(units=10, activation=\"softmax\")) # output layer 10 units-> 10 classes. softmax activation since it is multiclass classification\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDihWIErMGzh"
      },
      "source": [
        "None as first dimension in output shape of layers mean that batch size can be anything.\n",
        "\n",
        "More number of parameters in model gives the model quite a lot of flexibility to fit the training data, but it also means that the model runs the risk of overfitting, especially when you do not have a lot of training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzydnmSZwd1N",
        "outputId": "e467a5ad-a0b0-4187-ab89-0b3544f69cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# layers of a model can be listed as :\n",
        "\n",
        "print(model.layers)\n",
        "print(model.layers[0].name, model.layers[1].name, model.layers[2].name,model.layers[3].name)\n",
        "#print(model.get_layer('dense_2').name)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.layers.core.Flatten object at 0x7fe969a9fda0>, <tensorflow.python.keras.layers.core.Dense object at 0x7fe969aa36d8>, <tensorflow.python.keras.layers.core.Dense object at 0x7fe968053d30>, <tensorflow.python.keras.layers.core.Dense object at 0x7fe968062400>]\n",
            "flatten_3 dense_9 dense_10 dense_11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vU89DHYMG2S"
      },
      "source": [
        "All the parameters of a layer can be accessed using its get_weights() and\n",
        "set_weights() method. For a Dense layer, this includes both the connection weights\n",
        "and the bias terms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7_JVH14xuBY",
        "outputId": "86cf0b54-5069-4f42-a1f7-5e3e7098ced1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "hidden1=model.get_layer('dense_9')\n",
        "weights, biases = hidden1.get_weights()\n",
        "weights.shape, biases.shape, weights, biases"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((784, 300),\n",
              " (300,),\n",
              " array([[-1.5212674e-02,  6.6495880e-02, -5.4218397e-03, ...,\n",
              "          5.7591066e-02,  5.8487982e-02,  3.6486447e-02],\n",
              "        [-1.6607173e-02,  2.6657544e-02,  7.3698714e-02, ...,\n",
              "         -4.1087892e-02, -7.3400393e-02, -3.1902578e-02],\n",
              "        [-6.8335399e-02, -8.0563128e-05,  6.4519867e-02, ...,\n",
              "          1.1998147e-02, -4.2076692e-02,  3.9360724e-02],\n",
              "        ...,\n",
              "        [ 5.4183185e-02, -9.6232668e-03,  2.2241034e-02, ...,\n",
              "          3.0676998e-02,  3.4056358e-02, -7.0022076e-02],\n",
              "        [-3.1640995e-02,  2.5689021e-02,  1.3987489e-02, ...,\n",
              "         -2.1036703e-02, -6.3982889e-02, -4.7445640e-02],\n",
              "        [ 5.4960579e-02, -1.8498063e-02, -7.0042908e-04, ...,\n",
              "         -1.9669168e-02,  4.1053042e-02, -6.4697951e-02]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jcxr-smybr2"
      },
      "source": [
        "Notice that the Dense layer initialized the connection weights randomly (which is needed to break symmetry), and the biases were just initialized\n",
        "to zeros, which is fine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFcuWKR4ybuZ"
      },
      "source": [
        "If you ever want to use a different initialization method,\n",
        "you can set kernel_initializer (kernel is another name for the matrix of connection\n",
        "weights) or bias_initializer when creating the layer.\n",
        "\n",
        "https://keras.io/api/layers/initializers/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgo5LzToybw6"
      },
      "source": [
        "The shape of the weight matrix depends on the number of inputs.\n",
        "This is why it is recommended to specify the input_shape when\n",
        "creating the first layer in a Sequential model. However, if you do\n",
        "not specify the input shape, it’s okay: Keras will simply wait until it\n",
        "knows the input shape before it actually builds the model. This will\n",
        "happen either when you feed it actual data (e.g., during training),\n",
        "or when you call its build() method. Until the model is really\n",
        "built, the layers will not have any weights, and you will not be able\n",
        "to do certain things (such as print the model summary or save the\n",
        "model), so if you know the input shape when creating the model, it\n",
        "is best to specify it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rL3PDN4ybz0"
      },
      "source": [
        "### Compiling the Model\n",
        "After a model is created, you must call its compile() method to specify the loss function and the optimizer to use. Optionally, you can also specify a list of extra metrics to compute during training and evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ7gDWw-0Dxr"
      },
      "source": [
        "model.compile(optimizer=\"sgd\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNtscFZayb2x"
      },
      "source": [
        "Using loss=\"sparse_categorical_crossentropy\" is equivalent to\n",
        "loss=keras.losses.sparse_categorical_crossentropy. Similarly,\n",
        "optimizer=\"sgd\" is equivalent to optimizer=keras.optimiz\n",
        "ers.SGD() and metrics=[\"accuracy\"] is equivalent to\n",
        "metrics=[keras.metrics.sparse_categorical_accuracy] (when\n",
        "using this loss). We will use many other losses. See full lists at https://keras.io/losses/,\n",
        "https://keras.io/optimizers/ and https://keras.io/metrics/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9tDFSUq0rwM"
      },
      "source": [
        "# alternate compile using direct classes/functions\n",
        "model.compile(optimizer=keras.optimizers.SGD(), loss=keras.losses.sparse_categorical_crossentropy, metrics=[keras.metrics.sparse_categorical_accuracy])\n",
        "\n",
        "\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBjiZd9F1dch"
      },
      "source": [
        "### Loss selection for classification:\n",
        "\n",
        "First, we use the \"sparse_categorical_crossen\n",
        "tropy\" loss because we have sparse labels (i.e., for each instance there is just a target\n",
        "class index, from 0 to 9 in this case), and the classes are exclusive. If instead we had\n",
        "one target probability per class for each instance (such as one-hot vectors, e.g. [0.,\n",
        "0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would need\n",
        "to use the \"categorical_crossentropy\" loss instead. If we were doing binary classification\n",
        "(with one or more binary labels), then we would use the \"sigmoid\" (i.e.,\n",
        "logistic) activation function in the output layer instead of the \"softmax\" activation\n",
        "function, and we would use the \"binary_crossentropy\" loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4a6DACg1nc8"
      },
      "source": [
        "If you want to convert sparse labels (i.e., class indices) to one-hot\n",
        "vector labels, you can use the keras.utils.to_categorical()\n",
        "function. To go the other way round, you can just use the np.arg\n",
        "max() function with axis=1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSm0DlSK14HH"
      },
      "source": [
        "### Choice of optimizer:\n",
        "\"sgd\" simply means that we will train the model\n",
        "using simple Stochastic Gradient Descent. In other words, Keras will perform the\n",
        "backpropagation algorithm described earlier (i.e., reverse-mode autodiff + Gradient\n",
        "Descent). However there are more efficient optimizers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDigOiMo2AAN"
      },
      "source": [
        "### Metric's choice:\n",
        "For a classifier, it’s useful to measure its \"accuracy\" during training\n",
        "and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5PSzHA92NE9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHp1dlBA2NNA"
      },
      "source": [
        "### Training and Evaluating the Model:\n",
        "We simply need to call its fit()\n",
        "method. We pass it the input features (X_train) and the target classes (y_train), as\n",
        "well as the number of epochs to train (or else it would default to just 1, which would\n",
        "definitely not be enough to converge to a good solution). We also pass a validation set\n",
        "(this is optional): Keras will measure the loss and the extra metrics on this set at the\n",
        "end of each epoch, which is very useful to see how well the model really performs: if\n",
        "the performance on the training set is much better than on the validation set, your\n",
        "model is probably overfitting the training set (or there is a bug, such as a data mismatch\n",
        "between the training set and the validation set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVzqatpa2uU8",
        "outputId": "12e202b9-cd3c-417a-df6e-14268f67ce38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x=X_train, y=y_train, epochs=30, validation_data=(X_valid, y_valid))\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7075 - sparse_categorical_accuracy: 0.7682 - val_loss: 0.5053 - val_sparse_categorical_accuracy: 0.8316\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4873 - sparse_categorical_accuracy: 0.8309 - val_loss: 0.4586 - val_sparse_categorical_accuracy: 0.8442\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4423 - sparse_categorical_accuracy: 0.8452 - val_loss: 0.4195 - val_sparse_categorical_accuracy: 0.8580\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4140 - sparse_categorical_accuracy: 0.8543 - val_loss: 0.3998 - val_sparse_categorical_accuracy: 0.8628\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3955 - sparse_categorical_accuracy: 0.8616 - val_loss: 0.3885 - val_sparse_categorical_accuracy: 0.8648\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3776 - sparse_categorical_accuracy: 0.8669 - val_loss: 0.3965 - val_sparse_categorical_accuracy: 0.8564\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3648 - sparse_categorical_accuracy: 0.8711 - val_loss: 0.4027 - val_sparse_categorical_accuracy: 0.8520\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3526 - sparse_categorical_accuracy: 0.8743 - val_loss: 0.3571 - val_sparse_categorical_accuracy: 0.8744\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3420 - sparse_categorical_accuracy: 0.8786 - val_loss: 0.3426 - val_sparse_categorical_accuracy: 0.8788\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3320 - sparse_categorical_accuracy: 0.8811 - val_loss: 0.3540 - val_sparse_categorical_accuracy: 0.8722\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3244 - sparse_categorical_accuracy: 0.8842 - val_loss: 0.3499 - val_sparse_categorical_accuracy: 0.8800\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3158 - sparse_categorical_accuracy: 0.8867 - val_loss: 0.3361 - val_sparse_categorical_accuracy: 0.8786\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3084 - sparse_categorical_accuracy: 0.8897 - val_loss: 0.3267 - val_sparse_categorical_accuracy: 0.8850\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3009 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.3479 - val_sparse_categorical_accuracy: 0.8718\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2950 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.3192 - val_sparse_categorical_accuracy: 0.8860\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2892 - sparse_categorical_accuracy: 0.8964 - val_loss: 0.3212 - val_sparse_categorical_accuracy: 0.8828\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2827 - sparse_categorical_accuracy: 0.8976 - val_loss: 0.3314 - val_sparse_categorical_accuracy: 0.8838\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2780 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.3272 - val_sparse_categorical_accuracy: 0.8794\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2723 - sparse_categorical_accuracy: 0.9009 - val_loss: 0.3552 - val_sparse_categorical_accuracy: 0.8718\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2663 - sparse_categorical_accuracy: 0.9047 - val_loss: 0.3288 - val_sparse_categorical_accuracy: 0.8830\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2630 - sparse_categorical_accuracy: 0.9060 - val_loss: 0.3169 - val_sparse_categorical_accuracy: 0.8864\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2572 - sparse_categorical_accuracy: 0.9068 - val_loss: 0.3082 - val_sparse_categorical_accuracy: 0.8896\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2526 - sparse_categorical_accuracy: 0.9095 - val_loss: 0.3083 - val_sparse_categorical_accuracy: 0.8890\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2482 - sparse_categorical_accuracy: 0.9114 - val_loss: 0.3027 - val_sparse_categorical_accuracy: 0.8916\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2441 - sparse_categorical_accuracy: 0.9116 - val_loss: 0.3005 - val_sparse_categorical_accuracy: 0.8912\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2396 - sparse_categorical_accuracy: 0.9144 - val_loss: 0.3118 - val_sparse_categorical_accuracy: 0.8882\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2355 - sparse_categorical_accuracy: 0.9156 - val_loss: 0.3271 - val_sparse_categorical_accuracy: 0.8802\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2334 - sparse_categorical_accuracy: 0.9159 - val_loss: 0.2986 - val_sparse_categorical_accuracy: 0.8934\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2273 - sparse_categorical_accuracy: 0.9182 - val_loss: 0.3103 - val_sparse_categorical_accuracy: 0.8890\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2251 - sparse_categorical_accuracy: 0.9185 - val_loss: 0.3043 - val_sparse_categorical_accuracy: 0.8946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeOocqud2NPy"
      },
      "source": [
        "### Class weight:\n",
        "If the training set was very skewed, with some classes being overrepresented and others\n",
        "underrepresented, it would be useful to set the class_weight argument when\n",
        "calling the fit() method, giving a larger weight to underrepresented classes, and a\n",
        "lower weight to overrepresented classes. These weights would be used by Keras when\n",
        "computing the loss. If you need per-instance weights instead, you can set the sample_weight argument (it supersedes class_weight). This could be useful for example\n",
        "if some instances were labeled by experts while others were labeled using a\n",
        "crowdsourcing platform: you might want to give more weight to the former. You can\n",
        "also provide sample weights (but not class weights) for the validation set by adding\n",
        "them as a third item in the validation_data tuple.\n",
        "The fit() method returns a History object containing the training parameters (history.params), the list of epochs it went through (history.epoch), and most importantly\n",
        "a dictionary (history.history) containing the loss and extra metrics it\n",
        "measured at the end of each epoch on the training set and on the validation set (if"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWkGgHJf4ZnS",
        "outputId": "bfe9d6bf-5169-4da0-9f72-e532b851406f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history.params"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epochs': 30, 'steps': 1719, 'verbose': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdMlJ1rD4Ztt",
        "outputId": "3b0e8b55-9958-49e5-b8c0-4d2cbfe005ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "history.epoch"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7MBMQk44Zz2",
        "outputId": "bbaa3d88-b77e-4192-df6a-034bfb76a6bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history.history # contains history of loss and extra metrics it measured at the end of each epoch on the training set and on the validation set\n",
        "\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.7075010538101196,\n",
              "  0.4873378872871399,\n",
              "  0.4422578811645508,\n",
              "  0.4139818251132965,\n",
              "  0.39553722739219666,\n",
              "  0.3775596618652344,\n",
              "  0.3647879958152771,\n",
              "  0.35255977511405945,\n",
              "  0.34202131628990173,\n",
              "  0.3320041596889496,\n",
              "  0.32436203956604004,\n",
              "  0.3157702088356018,\n",
              "  0.30843308568000793,\n",
              "  0.30091583728790283,\n",
              "  0.29504725337028503,\n",
              "  0.28918275237083435,\n",
              "  0.282667875289917,\n",
              "  0.277959406375885,\n",
              "  0.27228882908821106,\n",
              "  0.2663315236568451,\n",
              "  0.26298779249191284,\n",
              "  0.2572055757045746,\n",
              "  0.25257357954978943,\n",
              "  0.24822993576526642,\n",
              "  0.24408622086048126,\n",
              "  0.2396194040775299,\n",
              "  0.2355285882949829,\n",
              "  0.23337918519973755,\n",
              "  0.22730204463005066,\n",
              "  0.2251386046409607],\n",
              " 'sparse_categorical_accuracy': [0.7681999802589417,\n",
              "  0.8308908939361572,\n",
              "  0.8452181816101074,\n",
              "  0.8543272614479065,\n",
              "  0.8615818023681641,\n",
              "  0.8668545484542847,\n",
              "  0.8711090683937073,\n",
              "  0.8742727041244507,\n",
              "  0.878563642501831,\n",
              "  0.8811091184616089,\n",
              "  0.884218156337738,\n",
              "  0.8866545557975769,\n",
              "  0.8896727561950684,\n",
              "  0.8914181590080261,\n",
              "  0.8940545320510864,\n",
              "  0.896399974822998,\n",
              "  0.897563636302948,\n",
              "  0.8997454643249512,\n",
              "  0.9009272456169128,\n",
              "  0.9046727418899536,\n",
              "  0.906000018119812,\n",
              "  0.906781792640686,\n",
              "  0.9094908833503723,\n",
              "  0.9114363789558411,\n",
              "  0.9116363525390625,\n",
              "  0.9144181609153748,\n",
              "  0.9155636429786682,\n",
              "  0.9158727526664734,\n",
              "  0.918181836605072,\n",
              "  0.9184545278549194],\n",
              " 'val_loss': [0.5053308010101318,\n",
              "  0.45861971378326416,\n",
              "  0.4195499122142792,\n",
              "  0.39976030588150024,\n",
              "  0.3884715139865875,\n",
              "  0.39649641513824463,\n",
              "  0.4027072787284851,\n",
              "  0.3570941686630249,\n",
              "  0.34258994460105896,\n",
              "  0.35396286845207214,\n",
              "  0.3499397933483124,\n",
              "  0.3360557556152344,\n",
              "  0.32669776678085327,\n",
              "  0.3478841185569763,\n",
              "  0.31919151544570923,\n",
              "  0.32121339440345764,\n",
              "  0.3314177989959717,\n",
              "  0.3271685838699341,\n",
              "  0.3551894724369049,\n",
              "  0.328818678855896,\n",
              "  0.31690168380737305,\n",
              "  0.3082010746002197,\n",
              "  0.3082580268383026,\n",
              "  0.3027384579181671,\n",
              "  0.3005337715148926,\n",
              "  0.31177404522895813,\n",
              "  0.3270954489707947,\n",
              "  0.29863062500953674,\n",
              "  0.31029415130615234,\n",
              "  0.30433908104896545],\n",
              " 'val_sparse_categorical_accuracy': [0.83160001039505,\n",
              "  0.8442000150680542,\n",
              "  0.8579999804496765,\n",
              "  0.8628000020980835,\n",
              "  0.864799976348877,\n",
              "  0.8564000129699707,\n",
              "  0.8519999980926514,\n",
              "  0.8744000196456909,\n",
              "  0.8787999749183655,\n",
              "  0.8722000122070312,\n",
              "  0.8799999952316284,\n",
              "  0.878600001335144,\n",
              "  0.8849999904632568,\n",
              "  0.8718000054359436,\n",
              "  0.8859999775886536,\n",
              "  0.8827999830245972,\n",
              "  0.8838000297546387,\n",
              "  0.8794000148773193,\n",
              "  0.8718000054359436,\n",
              "  0.8830000162124634,\n",
              "  0.8863999843597412,\n",
              "  0.8895999789237976,\n",
              "  0.8889999985694885,\n",
              "  0.8916000127792358,\n",
              "  0.8912000060081482,\n",
              "  0.8881999850273132,\n",
              "  0.8802000284194946,\n",
              "  0.8934000134468079,\n",
              "  0.8889999985694885,\n",
              "  0.894599974155426]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7-koS_G47rE",
        "outputId": "c8b7e019-914a-496b-83c2-406ec9be24aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "# If you create a Pandas DataFrame using this dictionary and call its plot()\n",
        "# method, you get the learning curves shown:\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjnq9-rF2NTH"
      },
      "source": [
        "### model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nVvJB4z5wEx",
        "outputId": "d5b31104-0bb4-4e27-ec6e-57348540233a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 84.5652 - sparse_categorical_accuracy: 0.8184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[84.56522369384766, 0.8184000253677368]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKWGl8Em2NVo"
      },
      "source": [
        "**Remember to resist the temptation to\n",
        "tweak the hyperparameters on the test set, or else your estimate of the generalization\n",
        "error will be too optimistic.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZz7pieM2NYL"
      },
      "source": [
        "### Making predictions with the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik2RF8hKA48t",
        "outputId": "ae6fc19e-de94-4c6e-cb85-59bc05e16f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "y_proba.round(2)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q2DsxsqBSiu",
        "outputId": "30803dd2-42e3-4f03-f421-648c20d88133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# to predict classes directly based on max probability:\n",
        "y_pred = np.argmax(model.predict(x=X_new), axis=-1)\n",
        "y_pred, np.array(class_names)[y_pred]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([9, 2, 1]), array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqTf1-hX2Nao"
      },
      "source": [
        ""
      ]
    }
  ]
}